apply plugin: 'java'

ext {
    // Project Metadata
    targetJavaVersion=11
    projectVersion = "1.0-SNAPSHOT"
    projectGroup = "gov.va"

    // Dependency Versions
    sparkVersion = "3.3.2"
    hapiVersion = "6.4.1"
    cqfVersion = "2.8.0"
}

compileJava {
    sourceCompatibility = "${targetJavaVersion}"
    targetCompatibility = "${targetJavaVersion}"
}

repositories {
    mavenCentral()
}

dependencies {    
    // Spark
    compileOnly "org.apache.spark:spark-sql_2.12:${sparkVersion}"
    testImplementation "org.apache.spark:spark-sql_2.12:${sparkVersion}"
    //testImplementation "org.slf4j:slf4j-simple:2.0.7"

    // HAPI
    implementation "ca.uhn.hapi.fhir:hapi-fhir-base:${hapiVersion}"
    implementation "ca.uhn.hapi.fhir:hapi-fhir-structures-r4:${hapiVersion}"
    implementation "ca.uhn.hapi.fhir:hapi-fhir-validation:${hapiVersion}"
    implementation "ca.uhn.hapi.fhir:hapi-fhir-validation-resources-r4:${hapiVersion}"

    // Testing
    testImplementation "org.junit.jupiter:junit-jupiter:5.9.3"
}

tasks.named("test", Test) {
    useJUnitPlatform()
}

test {
    jvmArgs = [
        // https://stackoverflow.com/questions/73465937/apache-spark-3-3-0-breaks-on-java-17-with-cannot-access-class-sun-nio-ch-direct
        '--add-opens=java.base/java.lang=ALL-UNNAMED',
        '--add-opens=java.base/java.lang.invoke=ALL-UNNAMED',
        '--add-opens=java.base/java.lang.reflect=ALL-UNNAMED',
        '--add-opens=java.base/java.io=ALL-UNNAMED',
        '--add-opens=java.base/java.net=ALL-UNNAMED',
        '--add-opens=java.base/java.nio=ALL-UNNAMED',
        '--add-opens=java.base/java.util=ALL-UNNAMED',
        '--add-opens=java.base/java.util.concurrent=ALL-UNNAMED',
        '--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED',
        '--add-opens=java.base/sun.nio.ch=ALL-UNNAMED',
        '--add-opens=java.base/sun.nio.cs=ALL-UNNAMED',
        '--add-opens=java.base/sun.security.action=ALL-UNNAMED',
        '--add-opens=java.base/sun.util.calendar=ALL-UNNAMED'
    ]
}